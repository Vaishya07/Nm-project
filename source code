import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
# Load the dataset
data = pd.read_csv('traffic_accident_data.csv')
# Display basic info
print("Dataset Overview:")
print(data.head())
# Handle Missing Values (if any)
data.fillna(method='ffill', inplace=True)
# Encode Categorical Features
label_encoders = {}
categorical_cols = data.select_dtypes(include=['object']).columns

for col in categorical_cols:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le
# Split the data
X = data.drop('Accident_Severity', axis=1)
y = data['Accident_Severity']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Exploratory Data Analysis
plt.figure(figsize=(10, 6))
sns.countplot(data=data, x='Weather_Conditions', hue='Accident_Severity')
plt.title('Accident Severity vs Weather Conditions')
plt.show()
plt.figure(figsize=(10, 6))
sns.countplot(data=data, x='Road_Type', hue='Accident_Severity')
plt.title('Accident Severity vs Road Type')
plt.show()
plt.figure(figsize=(10, 6))
sns.histplot(data=data, x='Traffic_Volume', hue='Accident_Severity', kde=True)
plt.title('Traffic Volume Distribution by Severity')
plt.show()
# Step 2: Model Training and Evaluation
# =============================

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, accuracy_score
import joblib
# Model 1: RandomForest Classifier
print("Training RandomForest Model...")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

print("RandomForest Classification Report:")
print(classification_report(y_test, y_pred_rf))
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf)}")

# Model 2: GradientBoosting Classifier
print("Training GradientBoosting Model...")
gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gb_model.fit(X_train, y_train)
y_pred_gb = gb_model.predict(X_test)

print("GradientBoosting Classification Report:")
print(classification_report(y_test, y_pred_gb))
print(f"Accuracy: {accuracy_score(y_test, y_pred_gb)}")
from sklearn.metrics import confusion_matrix, roc_curve, auc

# Confusion Matrix for Random Forest
cm_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(6, 6))
sns.heatmap(cm_rf, annot=True, fmt="d", cmap="Blues", xticklabels=['Low', 'Moderate', 'High'], yticklabels=['Low', 'Moderate', 'High'])
plt.title('Random Forest Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
# Confusion Matrix for Gradient Boosting
cm_gb = confusion_matrix(y_test, y_pred_gb)
plt.figure(figsize=(6, 6))
sns.heatmap(cm_gb, annot=True, fmt="d", cmap="Blues", xticklabels=['Low', 'Moderate', 'High'], yticklabels=['Low', 'Moderate', 'High'])
plt.title('Gradient Boosting Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
# Accuracy Comparison
rf_accuracy = accuracy_score(y_test, y_pred_rf)
gb_accuracy = accuracy_score(y_test, y_pred_gb)

print(f"Random Forest Accuracy: {rf_accuracy}")
print(f"Gradient Boosting Accuracy: {gb_accuracy}")
# Feature Importance for RandomForest
feature_importances = rf_model.feature_importances_
features = X.columns

# Create a dataframe for visualization
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=importance_df)
plt.title('Feature Importance (Random Forest)')
plt.show()
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score

# Binarize the output (one-vs-rest) for multi-class classification
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])  # Assuming 3 classes: 0, 1, 2
n_classes = y_test_bin.shape[1]

# Predict probabilities for both models
y_pred_prob_rf = rf_model.predict_proba(X_test)
y_pred_prob_gb = gb_model.predict_proba(X_test)

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))

# RandomForest ROC curve for each class
for i in range(n_classes):
    fpr_rf, tpr_rf, _ = roc_curve(y_test_bin[:, i], y_pred_prob_rf[:, i])
    roc_auc_rf = auc(fpr_rf, tpr_rf)
    plt.plot(fpr_rf, tpr_rf, lw=2, label=f'RandomForest Class {i} (AUC = {roc_auc_rf:.2f})')

# GradientBoosting ROC curve for each class
for i in range(n_classes):
    fpr_gb, tpr_gb, _ = roc_curve(y_test_bin[:, i], y_pred_prob_gb[:, i])
    roc_auc_gb = auc(fpr_gb, tpr_gb)
    plt.plot(fpr_gb, tpr_gb, lw=2, label=f'GradientBoosting Class {i} (AUC = {roc_auc_gb:.2f})')

# Diagonal line (no discrimination)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')

# Labeling and legend
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()
